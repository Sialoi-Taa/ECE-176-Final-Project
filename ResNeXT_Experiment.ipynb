{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cf6de2",
   "metadata": {},
   "source": [
    "# ResNeXT Experiment Notebook\n",
    "summary_goes_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f83ef",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87e0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340f0b4",
   "metadata": {},
   "source": [
    "**Making sure the GPU is available for increased speed for computations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c826f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "num_class = 100\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867dfbfc",
   "metadata": {},
   "source": [
    "## Preparing The Dataset\n",
    "We run the first cell to initialize our dataloader with our dataset, but also to find the mean and standard deviation inside the images of the dataset in order to normalize the dataset correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fdae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [tensor(0.5077), tensor(0.5077), tensor(0.5077)]\n",
      "std: [tensor(0.2120), tensor(0.2120), tensor(0.2120)]\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "    # No resizing\n",
    "    # No normalization for now\n",
    "])\n",
    "\n",
    "# Define paths to your train, val, and test folders\n",
    "train_path = './archive/train'\n",
    "val_path = './archive/test'\n",
    "test_path = './archive/test'\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Calculate mean and std for normalization\n",
    "mean = [0., 0., 0.]\n",
    "std = [0., 0., 0.]\n",
    "for img, _ in train_dataset:\n",
    "    for i in range(3):  # Iterate over channels\n",
    "        mean[i] += img[i, :, :].mean()\n",
    "        std[i] += img[i, :, :].std()\n",
    "\n",
    "num_samples = len(train_dataset)\n",
    "for i in range(3):  # Calculate mean and std per channel\n",
    "    mean[i] /= num_samples\n",
    "    std[i] /= num_samples\n",
    "\n",
    "print(f\"mean: {mean}\")\n",
    "print(f\"std: {std}\")\n",
    "\n",
    "# Define transformations with calculated mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize images\n",
    "])\n",
    "\n",
    "# Apply the new transformation to the datasets\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5106b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your train, val, and test folders\n",
    "train_path = './archive/train'\n",
    "val_path = './archive/test'\n",
    "test_path = './archive/test'\n",
    "\n",
    "# Define transformations with calculated mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "    transforms.Normalize((0.5077, 0.5077, 0.5077), (0.2120, 0.2120, 0.2120))  # Normalize images\n",
    "])\n",
    "\n",
    "# Apply the new transformation to the datasets\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "loader_val = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b86cf",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5a66ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on FER-2013 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: The accuracy of the model\n",
    "    \"\"\"\n",
    "    #print(f\"print_every: {print_every}\")\n",
    "    loss_list = []\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "            loss_list.append(loss.item())\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            #print(f\"t+1: {t+1}\")\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t + 1, loss.item()))\n",
    "                check_accuracy_part34(loader_test, model)\n",
    "                print()        \n",
    "    # Plotting the loss history during the training\n",
    "    plt.plot(loss_list)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Plot of Loss Over Iterations')\n",
    "    plt.show()\n",
    "    return check_accuracy_part34(loader_test, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52267dcf",
   "metadata": {},
   "source": [
    "# Experiment Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "742e7130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n",
      "Epoch 0, Iteration 10, loss = 1.8521\n",
      "Checking accuracy on test set\n",
      "Got 1770 / 7178 correct (24.66)\n",
      "\n",
      "Epoch 0, Iteration 20, loss = 1.7418\n",
      "Checking accuracy on test set\n",
      "Got 1660 / 7178 correct (23.13)\n",
      "\n",
      "Epoch 0, Iteration 30, loss = 1.7022\n",
      "Checking accuracy on test set\n",
      "Got 2239 / 7178 correct (31.19)\n",
      "\n",
      "Epoch 0, Iteration 40, loss = 1.7655\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1131/1965180917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1131/1715622981.py\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d, Iteration %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mcheck_accuracy_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_accuracy_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1131/1715622981.py\u001b[0m in \u001b[0;36mcheck_accuracy_part34\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "class MyResNet(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(MyResNet, self).__init__()\n",
    "        kernel_size = 5\n",
    "        self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(3, 64, (7,7), stride=2, padding=3),\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            nn.MaxPool2d(kernel_size, stride=2, padding=1),\n",
    "                            nn.ReLU(),\n",
    "                        )\n",
    "        self.conv2_x = nn.Sequential(\n",
    "                            nn.Conv2d(64, 64, kernel_size, padding=2),\n",
    "                            #nn.BatchNorm2d(64),\n",
    "                            #nn.ReLU(),\n",
    "                            #nn.Conv2d(64, 64, kernel_size, padding=2),\n",
    "                            #nn.ReLU(),\n",
    "                        )\n",
    "        self.conv3_x = nn.Sequential(\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(64, 128, kernel_size, padding=2),\n",
    "                            #nn.BatchNorm2d(128),\n",
    "                            #nn.ReLU(),\n",
    "                            #nn.Conv2d(128, 128, kernel_size, padding=2),\n",
    "                            #nn.ReLU(),\n",
    "                        )\n",
    "        self.conv4_x = nn.Sequential(\n",
    "                            nn.BatchNorm2d(128),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(128, 256, kernel_size, padding=2),\n",
    "                            #nn.BatchNorm2d(256),\n",
    "                            #nn.ReLU(),\n",
    "                            #nn.Conv2d(256, 256, kernel_size, padding=2),\n",
    "                            #nn.ReLU(),\n",
    "                        )\n",
    "        self.conv5_x = nn.Sequential(\n",
    "                            nn.BatchNorm2d(256),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(256, 512, kernel_size, stride=2, padding=2),\n",
    "                            #nn.BatchNorm2d(512),\n",
    "                            #nn.ReLU(),\n",
    "                            #nn.Conv2d(512, 512, kernel_size, padding=2),\n",
    "                            #nn.ReLU(),\n",
    "                        )\n",
    "        self.conv6_x = nn.Sequential(\n",
    "                            #nn.BatchNorm2d(256),\n",
    "                            nn.BatchNorm2d(512),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(512, 1024, kernel_size, stride=2, padding=2),\n",
    "                            #nn.BatchNorm2d(1024),\n",
    "                            #nn.ReLU(),\n",
    "                            #nn.Conv2d(1024, 1024, kernel_size, padding=2),\n",
    "                            #nn.ReLU(),\n",
    "                        )\n",
    "        self.last_x = nn.Sequential(\n",
    "                            #nn.BatchNorm2d(512),\n",
    "                            nn.BatchNorm2d(1024),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d((2, 2)),\n",
    "                            nn.Flatten(),\n",
    "                            nn.Linear(1024, 1000),\n",
    "                            nn.Linear(1000, 100),\n",
    "                        )\n",
    "        self.skip_connection1 = nn.Sequential(\n",
    "                            nn.Conv2d(64, 64, (1,1), stride=1, padding=0),\n",
    "                        )\n",
    "        self.skip_connection2 = nn.Sequential(\n",
    "                            nn.Conv2d(64, 128, (1,1), stride=1, padding=0),\n",
    "                        )\n",
    "        self.skip_connection3 = nn.Sequential(\n",
    "                            nn.Conv2d(128, 256, (1,1), stride=1, padding=0),\n",
    "                        )\n",
    "        self.skip_connection4 = nn.Sequential(\n",
    "                            nn.Conv2d(256, 512, (1,1), stride=2, padding=0),\n",
    "                        )\n",
    "        self.skip_connection5 = nn.Sequential(\n",
    "                            nn.Conv2d(512, 1024, (1,1), stride=2, padding=0),\n",
    "                        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        output = self.conv1(x)\n",
    "        skip = self.skip_connection1(output)\n",
    "        \n",
    "        output = self.conv2_x(output)\n",
    "        output += skip\n",
    "        output2 = output\n",
    "        output3 = output\n",
    "        output4 = output\n",
    "        skip = self.skip_connection2(output)\n",
    "        skip2 = self.skip_connection2(output2)\n",
    "        skip3 = self.skip_connection2(output3)\n",
    "        \n",
    "        output = self.conv3_x(output)\n",
    "        output2 = self.conv3_x(output2)\n",
    "        output3 = self.conv3_x(output3)\n",
    "        output += skip\n",
    "        output2 += skip2\n",
    "        output3 += skip3\n",
    "        skip = self.skip_connection3(output)\n",
    "        skip2 = self.skip_connection3(output2)\n",
    "        skip3 = self.skip_connection3(output3)\n",
    "        \n",
    "        output = self.conv4_x(output)\n",
    "        output2 = self.conv4_x(output2)\n",
    "        output3 = self.conv4_x(output3)\n",
    "        output += skip\n",
    "        output2 += skip2\n",
    "        output3 += skip3\n",
    "        skip = self.skip_connection4(output)\n",
    "        skip2 = self.skip_connection4(output2)\n",
    "        skip3 = self.skip_connection4(output3)\n",
    "        \n",
    "        output = self.conv5_x(output)\n",
    "        output2 = self.conv5_x(output2)\n",
    "        output3 = self.conv5_x(output3)\n",
    "        skip = self.skip_connection5(output)\n",
    "        skip2 = self.skip_connection5(output2)\n",
    "        skip3 = self.skip_connection5(output3)\n",
    "        \n",
    "        output = self.conv6_x(output)\n",
    "        output2 = self.conv6_x(output2)\n",
    "        output3 = self.conv6_x(output3)\n",
    "        output += output2 + output3 + skip + skip2 + skip3\n",
    "        \n",
    "        scores = self.last_x(output)\n",
    "        return scores\n",
    "\n",
    "model = MyResNet()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.00005)\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "print_every = 100\n",
    "train_part34(model, optimizer, epochs=10)\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0252a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 2440 / 7178 correct (33.99)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3399275564224018"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks your accuracy\n",
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c2a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136a5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc435f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792cf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186072a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
